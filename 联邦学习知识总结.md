# 一、分布式机器学习



## 1. 一些概念

### 1.1 定义

**分布式机器学习**（Distributed ML, **DML**）

组成部分：n个工作者，一个中心服务器，轴辐结构/星形拓扑结构
基本流程：

1. 训练数据分片，每个工作者占有一个
2. 工作者在本地执行梯度下降（SGD）
3. 得到的本地梯度和模型参数发送到服务器
4. 服务器对参数进行聚合（如加权平均）得到全局梯度和模型参数

### 1.2 分类

+ 面向扩展性的DML
优势：克服了训练数据的集中存储需求，结合云计算
应用：横向划分数据集的场景，训练数据的子集存储在不同的计算单元实体中

+ 面向隐私保护的DML
侧重：数据隐私和数据安全
常应用：纵向划分数据集的场景，不同参与放各自持有的训练数据具有相同的训练样本ID和不同的数据特征。

### 1.3 pytorch实现分布式计算

​	torch.distributed
+ 允许一个模型依逻辑分割为若干部分（例如CNN的一些层在一个部分，另一些层在另一个部分），然后置于不同的计算设备中。
+ 利用消息传递技术，允许每个进程与其它进程通信，不同于多进程包（torch.multiprocessing），进程可以使用不同的通信后端，且不必在同一台机器上执行



## 2. 面向扩展性的DML

传统ML的缺陷

+ **内存短缺**: GPU内存小, 训练不了,太慢,epoch小导致结果不好等
+ **训练时间长**: 训练太久导致调参不方便 

面向扩展性的DML的解决方案:

### 2.1 数据并行
分两类:(区别)
1. 同步训练: 每个计算节点负责总的训练数据的各个分片
2. 异步训练: 每个计算节点只负责本地的训练数据

共同点: 每个计算节点执行完模型更新步骤后, 每个计算节点产生的梯度(模型参数)会被发送到服务器,服务器接收所有结果进行聚合

应用场景:
+ 数据过大导致单一节点存不下
+ 并行计算速度快

### 2.2 模型并行

主要目的: 避免内存容量限制
细节理解: 例如将CNN中的每一层/某几层分别存在一台设备中, 前向/反向传播时以串行输入输出的方式进行

### 2.3 图并行

### 2.4 任务并行

例如一个应用程序创建多个线程, 并行处理, 每个线程负责不同的操作



## 3. 面向隐私的DML

### 3.1 隐私保护方法

1. 模糊处理

随机化, 添加噪声, 修改数据使其用于某一级别的隐私. (差分隐私方法)

2. 密码学方法

不将输入值传给其它参与方, 不使用明文传输. (安全多方计算, 不经意传输, 秘密共享, 混淆电路, 同态加密)

（同态加密-知乎https://zhuanlan.zhihu.com/p/77478956）

### 3.2 面向隐私保护的梯度下降方法

1. 代数方法
2. 稀疏梯度更新
3. 模糊处理方法
4. 密码学方法



# 二、横向联邦学习

+ 通俗理解:
	两家银行,有各自的客户群,且交集很小,但业务类型相似,即数据集的特征空间相同.将太慢联合起来可以进行联邦学习 
+ 挑战难题:
	系统安全性
## 1. 横向联邦学习架构

### 1.1 客户-服务器架构

+ 架构组成：K个参与方/客户/用户，服务器/参数服务器/聚合服务器，呈一串多形状。**中心化**
+ 训练流程：
    1. 各参与方在**本地**计算模型梯度，使用同态加密、差分隐私、秘密共享等加密技术，掩饰梯度信息，并将**加密后的梯度**发送给服务器。
    2. 服务器进行**安全聚合**操作，例如使用基于同态加密的加权平均。
    3. 服务器将聚合后的结果发送给各个参与方。
    4. 各参与方对受到的梯度进行**解密**，并使用解密后的梯度结果更新模型参数。
    
+ 联邦平均算法（对比P~57~）
	1. 梯度平均
	2. 模型平均

### 1.2 对等（P2P）架构

+ 架构组成：K个参与方/训练方，每个点地位对等，互相之间有安全链路连接。**去中心化**
+ 训练/信息传输方式：
	1. 循环传输：
		K个参与方连成一个圈，按顺序依次更新同一个模型，直到收敛或	到时间
	2. 随机传输：
		第i个参与方随机传到下一方（随机数选取有规则），直到结束
+ 对比：
	1. 没有中心服务器，是优点，因为服务器一般难以建立
	2. 缺点是训练耗时长，因为权重不是分批更新而是连续更新
+ 备注：
  + ”完全分散式学习“也是去中心化的结构，但它允许有中心节点的存在，只是不参与训练而是更加轻松的任务，负责管控各个节点。

### 1.3 全局模型评估

+ 本地模型性能：某一参与方、本地测试集
+ 全局模型性能：所有参与方、所有测试集

1. 客户-服务器架构：

 	对每个参与方使用本地测试集，总体训练好的模型进行评估，得到每个参与方的N~TP~，N~FP~，N~TN~，N~FN~，再加一起算出全局评估指标
2. 对等架构：
	一种解决方案是选取某一个参与方当作”服务器“，但这样对它负担太大，不适合于IoT设备


## 2. 联邦平均算法



# 三、FATE工具介绍

##  1. FATE

（Federated AI Technology Enabler）
###  1）概述
定义为平台/框架。相比于python的从零开发，FATE提供了完善的建模工具，构建联邦学习模型简单方便，用户不需了解太多底层原理，适合开发工业级产品。
### 2）目前提供的功能
- 基于数据隐私保护的分布式安全计算框架
- 为ML、DL、TL等常用算法提高高性能的安全计算支持
- 支持包括同态加密，秘密共享等高性能的安全计算协议
### 3）安装与部署
仅支持Linux和Mac。最新LTS版本是FATE v1.5
1. 原生部署
	需要配置必要的开发环境和依赖库。又分为单机部署和集群部署。单机部署适合初级开发者，可以从docker镜像安装。集群部署适合多方参与的大数据场景 。
2. KubeFATE部署
	不需要安装依赖库。适用于云环境。有Docker Compose和Kubenetes两种部署方式。
### 4）编程范式
- 组件化配置：用户拆解训练任务，每一个任务以组件的方式通过有向无环图连接。在配置文件中配置训练参数。即用户只用提交修改配置文件即可直接执行联邦学习训练。
- 脚本编程：提供API接口，类似直接使用python编程。（目前支持较少，相关文档较少）

















